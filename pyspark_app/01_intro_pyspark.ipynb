{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark - Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un video introductorio: https://www.youtube.com/watch?v=ymtq8yjmD9I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark es la API de Python para Apache Spark. Pemrite procesar datos a gran escala y en tiempo real en un entorno distribuido utilizando Python. Además, proporciona una shell para analizar los datos interactivamente.\n",
    "\n",
    "PySpark aprovecha el poder de Apache Spark para poder procesar y analizar datos de cualquier tamaño desde Python.\n",
    "\n",
    "PySpark admite todas las funciones existentes en Apache Spark tales como Spark SQL, DataFrames, Structured Streaming, Machine Learning y Spark Core\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Getting Started](images/intro.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL and DataFrames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparlSQL es el módulo de Apache Spark para trabajar con datos estructurados. Permite combinar queries de SQL con las funciones de Spark a través de DataFrames. Permite leer, escribir, transformar y analizar datos de manera eficiente aprovechando las funcionalidades de Spark. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La API de Pandas permite escalar tareas de procesamiento de datos a cualquier tamaño ejecutandolas de manera distribuida. La API pemrite migrar aplicaciones a Spark sin necesidad de modificar el código. Principalmente es útil cuando queremos utilizar un análisis hecho en Pandas con datos de mayor magintud. \n",
    "\n",
    "El objetivo de la API es que la transición de pandas a Spark sea sencilla. Sin embargo, no hay que dejar de lado las funciones que por sí solo tiene PySpark.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Streaming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured Streaming se refiere a un motor de procesamiento escalable y tolerante a fallas construido sobre el motor de Spark SQL. Permite ejecutar de manera incremental y continua operaciones actualizando los resultados conforme van llegando."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, PySpark cuenta con una librería de Machine Learning escalable (MLlib) que proporciona un conjunto uniforme de APIs que ayudan a los usuarios a crear, ajustar y escalar pipelines prácticos de machine learnning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Core and RDDs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Core es el motor principal de ejecución general de Spark. Sobre el se construyen todas las fucnionalidades anteriormente descritas. Además, proporciona RDDs (Resilient Distributed Datasets) y capacidades de cómputo en memoria. \n",
    "\n",
    "Es importante mencionar que utilizar RDDs puede ser difícil y no se obtiene el beneficio de las capacidades de optimización de consutlas en Spark. Por lo mismo, es más recomendable utilizar las funciones dentro de los DataFrames en Spark en lugar de RDDs ya que permite expresar las cosas más fácilmente y generar queries de manera automática."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
